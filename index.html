<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="O-TensoRF: Mitigating Floating Artifacts through Imposing Occlusion Regularization">
  <meta name="keywords" content="NeRF, TensoRF, Sparse-View, Face Reconstuction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TWINGS: Thin Plate Splines Warp-aligned Initialization for Sparse-View Gaussian Splatting</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
    </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">O-TensoRF: Mitigating Floating Artifacts through Imposing Occlusion Regularization</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/sandokim?tab=repositories">Hyeseong Kim</a>,</span>
            <span class="author-block">
              <a href="">Jungbin Cho,</span>
            <span class="author-block">
              <a href="">Deukhee Lee,</span>
            <span class="author-block">
              <a href="">Dosik Hwang</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openaccess.thecvf.com/content/ICCV2023W/RHWC/papers/Jang_VSCHH_2023_A_Benchmark_for_the_View_Synthesis_Challenge_of_ICCVW_2023_paper.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://openaccess.thecvf.com/ICCV2023_workshops/RHWC#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/sandokim/o-tensorf-official"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The ILSH dataset consists of 52 subjects with 24 views each which can be thought of as a sparse view problem for a novel view synthesis task. Sparse views lead to floating artifacts, degrading the quality of novel views. To overcome this problem, we exclude certain views during training, and adopt an occlusion regularization term allowing us to render high quality novel views.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-centered">
          <img src="./static/images/fig2.jpg"
               alt="O-TensoRF Pipeline"
               style="width: 100%; max-width: 100%; margin-bottom: 1rem;"/>
        </div>
        <div class="content has-text-justified">
          <p>
            We introduce occlusion regularization to reduce the floating artifacts commonly encountered in few-shot neural rendering tasks. The key idea of this regularization term is to penalize the density fields near the camera. Additionally, we find it beneficial to exclude all the backside views in the preprocessing step to avoid floating artifacts.
          </p>
        </div>
      </div>
    </div>
    <!--/ Method. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results</h2>
        <div class="content has-text-centered">
          <img src="./static/images/fig2.pdf"
               alt="Baseline without backviews"
               style="width: 100%; max-width: 100%; margin-bottom: 1rem;"/>
        </div>
        <div class="content has-text-justified" style="margin-bottom: 2rem;">
          <p>
            Improvement when trained without backviews. For sparse view settings such as ILSH, excluding certain views is beneficial for rendering novel views
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./static/images/fig3.pdf"
               alt="Baseline with occlusion regularization"
               style="width: 100%; max-width: 100%; margin-bottom: 1rem;"/>
        </div>
        <div class="content has-text-justified" style="margin-bottom: 2rem;">
          <p>
            Improvements using occlusion regularization. Occlusion regularization is effective at removing floaters in the vicinity of the camera.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./static/images/fig4.pdf"
               alt="Our method"
               style="width: 100%; max-width: 100%; margin-bottom: 1rem;"/>
        </div>
        <div class="content has-text-justified">
          <p>
            Qualitative comparison on ILSH dataset. Near-camera floaters are prominent in our baseline results while our method reconstructs images with fewer floaters.
          </p>
        </div>
      </div>
    </div>
    <!--/ Results. -->
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@InProceedings{Jang_2023_ICCV,
      author    = {Jang, Youngkyoon and Zheng, Jiali and Song, Jifei and Dhamo, Helisa and P\'erez-Pellitero, Eduardo and Tanay, Thomas and Maggioni, Matteo and Shaw, Richard and Catley-Chandar, Sibi and Zhou, Yiren and Deng, Jiankang and Zhu, Ruijie and Chang, Jiahao and Song, Ziyang and Yu, Jiahuan and Zhang, Tianzhu and Nguyen, Khanh-Binh and Yang, Joon-Sung and Dogaru, Andreea and Egger, Bernhard and Yu, Heng and Gupta, Aarush and Julin, Joel and Jeni, L\'aszl\'o A. and Kim, Hyeseong and Cho, Jungbin and Hwang, Dosik and Lee, Deukhee and Kim, Doyeon and Seo, Dongseong and Jeon, SeungJin and Choi, YoungDon and Kang, Jun Seok and Seker, Ahmet Cagatay and Ahn, Sang Chul and Leonardis, Ales and Zafeiriou, Stefanos},
      title     = {VSCHH 2023: A Benchmark for the View Synthesis Challenge of Human Heads},
      booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops},
      month     = {October},
      year      = {2023},
      pages     = {1121-1128}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <h2 class="title is-4">Acknowledgment</h2>
          <p>
            This website is licensed under a <a rel="license"
                                                href="https://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to the <a
              href="https://github.com/nerfies/nerfies.github.io">original page</a> in the footer.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
